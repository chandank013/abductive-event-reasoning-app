# Abductive Event Reasoning (AER) System

A comprehensive framework for identifying plausible causes of real-world events using large language models and retrieval-augmented generation. Built for SemEval 2026 Task 12.


## ğŸ¯ Project Overview

The Abductive Event Reasoning task is framed as a multiple-choice question answering problem, evaluating large language models' ability to identify the most plausible direct cause of a real-world event based on textual evidence.

### Task Definition

Each instance consists of:
- **Event**: A short description of an observed real-world event
- **Context**: Retrieved documents related to the event (including distractor documents)
- **Options (A-D)**: Four candidate explanations, where:
  - One or more may be correct
  - Option D is typically: "The information provided is insufficient to determine the cause"

### Evaluation Metric

- âœ… Full match with correct answers â†’ 1 point
- âš ï¸ Partial match â†’ 0.5 point
- âŒ Wrong or invalid selection â†’ 0 points

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€â”€ abstract/                # Abstract and documentation
â”‚   â”œâ”€â”€ abstract.md          # This abstract md file
â”‚   â””â”€â”€ abstract.docs          # This abstract file
â”œâ”€â”€ .ebextensions/          # AWS Elastic Beanstalk config (if deploying)
â”œâ”€â”€ .git/                   # Git repository
â”œâ”€â”€ dataset/                # Dataset files
â”‚   â”œâ”€â”€ validation
â”‚   â”‚    â”œâ”€â”€ question.jsonl
â”‚   â”‚    â””â”€â”€ docs.jsonl
â”‚   â”œâ”€â”€ question.jsonl
â”‚   â””â”€â”€ docs.jsonl
â”‚
â”œâ”€â”€ models/                 # Trained models
â”‚   â””â”€â”€ best_baseline_model.pkl
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â”œâ”€â”€ EDA.ipynb          # Exploratory Data Analysis
â”‚   â””â”€â”€ Model_Training.ipynb  # Model training and tuning
â”‚
â”œâ”€â”€ static/                 # Static files
â”‚   â””â”€â”€ images/            # Images and plots
â”‚       â”œâ”€â”€ logo.jpg
â”‚       â”œâ”€â”€ preview1.png
â”‚       â””â”€â”€ preview2.png
â”‚
â”œâ”€â”€ templates/              # HTML templates
â”‚   â”œâ”€â”€ landing.html       # Landing page
â”‚   â”œâ”€â”€ index.html         # Prediction page
â”‚
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ abstract.md            # Project abstract
â”œâ”€â”€ COMPLETE_SYSTEM_SUMMARY.md           # Complete system summary of project
â”œâ”€â”€ config.py               # Configuration file
â”œâ”€â”€ quick_start.py          # Quick start script
â”œâ”€â”€ quick_start.py          # Quick start script
â”œâ”€â”€ application.py          # Flask application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ septup.py              # Setup script
â””â”€â”€ SYSTEM_ARCHITECTURE.txt   # System architecture description
```

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- 8GB+ RAM (for BERT models)
- CUDA-compatible GPU (optional, for faster training)

### Step 1: Clone Repository

```bash
git clone https//github.com/chandank013/abductive-event-reasoning.git
cd abductive-event-reasoning
```

### Step 2: Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Download BERT Model (First Time Only)

The BERT model will be automatically downloaded when you first run the training notebook or application.

## ğŸ“Š Data Preparation

### 1. Prepare Your Data

Ensure your data files are in the correct format:

**question.jsonl:**
```json
{
    "topic_id": 1,
    "question": "The Iranian government issued an intercity travel ban...",
    "option_A": "U.S. port closures",
    "option_B": "COVID-19 lockdowns",
    "option_C": "Economic sanctions",
    "option_D": "Insufficient information",
    "answer": "B"
}
```

**docs.jsonl:**
```json
{
    "topic_id": 1,
    "docs": [
        {
            "title": "Document Title",
            "content": "Document content here..."
        }
    ]
}
```

### 2. Run Preprocessing

Open and run `notebooks/EDA.ipynb` to:
- Load and explore data
- Preprocess text
- Generate visualizations
- Save cleaned data

## ğŸ”¬ Model Training

### Multi-Algorithm Approach

The system trains and compares **6 different architectures**:

1. **BERT Baseline** - Standard BERT with feedforward classifier
2. **RoBERTa Baseline** - Improved pre-training, better tokenization
3. **RoBERTa + BiLSTM + Attention** - Sequential modeling with attention â­
4. **Longformer** - Handles long contexts up to 4096 tokens
5. **DistilBERT** - Fast and lightweight (60% faster inference)
6. **Hierarchical Attention** - Dual-level attention mechanism â­â­

### Hyperparameter Tuning

Each model is trained with automatic hyperparameter tuning:

- **Learning Rate**: [1e-5, 2e-5, 3e-5]
- **Dropout**: [0.2, 0.3, 0.4]
- **Hidden Sizes**: [256, 384, 512, 768]
- **Batch Sizes**: [4, 8, 16, 32]
- **~4 trials per model** = 24 total trainings

The system automatically:
- Trains each model with different hyperparameters
- Evaluates on validation set
- Selects best configuration
- Retrains best model on combined train+val data
- Finds optimal threshold
- Saves best performing model

### 1. Run Training Notebook

Open and run `notebooks/Model_Training.ipynb` to:
- Train all 6 model architectures
- Perform hyperparameter tuning for each
- Compare model performance
- Automatically select and save best model
- Generate comprehensive visualizations

### Training Output

The training process will:
- Train ~24 model variants (6 architectures Ã— 4 hyperparameter sets)
- Take 2-4 hours on GPU / 8-12 hours on CPU
- Generate comparison visualizations
- Save best model to `models/longformer.pkl`
- Create detailed results CSV

## ğŸŒ Running the Application

### Development Mode

```bash
python application.py
```

The application will be available at `http://localhost:5000`

### Production Mode

```bash
gunicorn -w 4 -b 0.0.0.0:8000 application:app
```

## ğŸ–¥ï¸ Using the Web Interface

### 1. Landing Page
- Overview of the AER system
- Key features and capabilities
- Navigation to different sections

### 2. Prediction Page
- Enter target event description
- Provide 4 possible causes (A, B, C, D)
- Select model type
- Get predictions with confidence scores


## ğŸ“ˆ Model Performance

### Best Model Results

```
**Best Performing Model:** Longformer Baseline

| Metric | Performance |
|--------|-------------|
| Validation Macro F1 | 61.52% |
| Exact Match Accuracy | 25.00% |
| Optimal Threshold | 45.0% |
```

## ğŸ”§ API Usage

### Prediction Endpoint

```python
import requests

url = "http://localhost:5000/api/predict"

data = {
    "event": "The Iranian government issued a travel ban",
    "option_a": "U.S. port closures",
    "option_b": "COVID-19 lockdowns",
    "option_c": "Economic sanctions",
    "option_d": "Insufficient information",
    "model": "Baseline"
}

response = requests.post(url, json=data)
result = response.json()

print(result)
# Output:
# {
#     "success": True,
#     "result": {
#         "predictions": {
#             "A": 0.23,
#             "B": 0.87,
#             "C": 0.45,
#             "D": 0.12
#         },
#         "recommended": "B",
#         "confidence": {
#             "A": "23.0%",
#             "B": "87.0%",
#             "C": "45.0%",
#             "D": "12.0%"
#         }
#     }
# }
```

### Model Info Endpoint

```python
response = requests.get("http://localhost:5000/api/model-info")
info = response.json()
print(info)
```

## ğŸ› ï¸ Customization

### Training Custom Models

Edit `notebooks/Model_Training.ipynb` to:
- Adjust hyperparameters
- Add new model architectures
- Modify training loop
- Change evaluation metrics

### Modifying UI

Edit templates in `templates/` folder:
- `landing.html` - Landing page
- `index.html` - Prediction interface
- Custom CSS in `<style>` tags

### Adding New Features

1. Add route in `application.py`:
```python
@app.route('/predict')
def new_feature():
    return render_template('landing.html')
```

2. Create template in `templates/landing.html`

## ğŸ“ Troubleshooting

### Common Issues

**1. CUDA Out of Memory**
```python
# Reduce batch size in training
BATCH_SIZE = 4  # or 2
```

**2. Model Not Loading**
```bash
# Ensure model file exists
ls models/best_baseline_model.pkl

# Retrain if needed
jupyter notebook notebooks/Model_Training.ipynb
```

**3. Port Already in Use**
```bash
# Change port in application.py
app.run(port=5001)
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request


## ğŸ™ Acknowledgments

- SemEval 2026 Task 12 organizers
- Hugging Face Transformers library
- PyTorch team
- Flask framework

## ğŸ“§ Contact

For questions or issues, please open an issue on GitHub or contact the development team.

---

**Built with â¤ï¸ for SemEval 2026 Task 12**